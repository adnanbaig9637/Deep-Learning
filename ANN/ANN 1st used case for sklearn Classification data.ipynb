{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838ec45a",
   "metadata": {},
   "source": [
    "**Type of Loss function in Classification task**\n",
    "* **For Binary Classification--Log Loss Loss Function also called as Binary Cross Entropy Loss Function.**\n",
    "* **For Multiclass Classification-- Multiclass log loss also called as Categorical Cross Entropy. OHE is necessory**\n",
    "* **For Multiclass classification-- Sparse Categorical Cross Entropy. Integer Based Encoding is necessory.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e45d4",
   "metadata": {},
   "source": [
    "### Binary Cross Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c39b0",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d49fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466da0b",
   "metadata": {},
   "source": [
    "**Creating Classification Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612782ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=3000, n_features=20, n_classes=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6396bf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2ccaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0cf794e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "#For sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a9eb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6049a103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52461c2b",
   "metadata": {},
   "source": [
    "**Binary Cross Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4935d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(20,)))\n",
    "model.add(Dense(units=4, activation='sigmoid', use_bias=True))\n",
    "model.add(Dense(units=6, activation='sigmoid', use_bias=True))\n",
    "model.add(Dense(units=1, activation='sigmoid', use_bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0772cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m84\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m30\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m7\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121</span> (484.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121\u001b[0m (484.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121</span> (484.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121\u001b[0m (484.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96c0a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18dfbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import F1Score, Precision, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "074b7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss ='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "452e9d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.6773 - val_accuracy: 0.6438 - val_loss: 0.6790\n",
      "Epoch 2/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.6744 - val_accuracy: 0.6458 - val_loss: 0.6786\n",
      "Epoch 3/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6518 - loss: 0.6770 - val_accuracy: 0.6458 - val_loss: 0.6783\n",
      "Epoch 4/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6688 - loss: 0.6754 - val_accuracy: 0.6521 - val_loss: 0.6779\n",
      "Epoch 5/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.6751 - val_accuracy: 0.6562 - val_loss: 0.6776\n",
      "Epoch 6/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6898 - loss: 0.6733 - val_accuracy: 0.6562 - val_loss: 0.6772\n",
      "Epoch 7/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.6730 - val_accuracy: 0.6562 - val_loss: 0.6768\n",
      "Epoch 8/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6749 - loss: 0.6739 - val_accuracy: 0.6562 - val_loss: 0.6765\n",
      "Epoch 9/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6738 - loss: 0.6739 - val_accuracy: 0.6583 - val_loss: 0.6761\n",
      "Epoch 10/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.6737 - val_accuracy: 0.6583 - val_loss: 0.6757\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f48fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6645833253860474,\n",
       "  0.6661458611488342,\n",
       "  0.6630208492279053,\n",
       "  0.6666666865348816,\n",
       "  0.675000011920929,\n",
       "  0.6697916388511658,\n",
       "  0.6755208373069763,\n",
       "  0.6770833134651184,\n",
       "  0.6796875,\n",
       "  0.6807291507720947],\n",
       " 'loss': [0.6767284870147705,\n",
       "  0.6763737201690674,\n",
       "  0.6760299801826477,\n",
       "  0.6756690740585327,\n",
       "  0.6753095984458923,\n",
       "  0.6749398112297058,\n",
       "  0.6745688915252686,\n",
       "  0.6741994619369507,\n",
       "  0.6738078594207764,\n",
       "  0.6734253168106079],\n",
       " 'val_accuracy': [0.643750011920929,\n",
       "  0.6458333134651184,\n",
       "  0.6458333134651184,\n",
       "  0.6520833373069763,\n",
       "  0.65625,\n",
       "  0.65625,\n",
       "  0.65625,\n",
       "  0.65625,\n",
       "  0.6583333611488342,\n",
       "  0.6583333611488342],\n",
       " 'val_loss': [0.678955614566803,\n",
       "  0.6786082983016968,\n",
       "  0.6782671213150024,\n",
       "  0.6779035925865173,\n",
       "  0.677560567855835,\n",
       "  0.6771848201751709,\n",
       "  0.6768271923065186,\n",
       "  0.6764583587646484,\n",
       "  0.6760966181755066,\n",
       "  0.6757187247276306]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9447077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x133d5474c10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,11), history.history['loss'], label = 'Training loss')\n",
    "plt.plot(range(1,11), history.history['val_accuracy'], label = 'Validattion loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea6764",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef62adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4672876 ],\n",
       "       [0.46574306],\n",
       "       [0.4726326 ],\n",
       "       [0.49743918],\n",
       "       [0.5130811 ],\n",
       "       [0.5397128 ],\n",
       "       [0.48088416],\n",
       "       [0.48146844],\n",
       "       [0.49101526],\n",
       "       [0.52638155],\n",
       "       [0.48902532],\n",
       "       [0.5342828 ],\n",
       "       [0.4845991 ],\n",
       "       [0.4840456 ],\n",
       "       [0.4985901 ],\n",
       "       [0.53384423],\n",
       "       [0.5378103 ],\n",
       "       [0.525396  ],\n",
       "       [0.46578804],\n",
       "       [0.48769617],\n",
       "       [0.459102  ],\n",
       "       [0.5452011 ],\n",
       "       [0.46880275],\n",
       "       [0.54615235],\n",
       "       [0.4819449 ],\n",
       "       [0.4952479 ],\n",
       "       [0.53815067],\n",
       "       [0.52594924],\n",
       "       [0.4959753 ],\n",
       "       [0.5102338 ],\n",
       "       [0.48657534],\n",
       "       [0.4832652 ],\n",
       "       [0.50309956],\n",
       "       [0.49568146],\n",
       "       [0.50406355],\n",
       "       [0.48469338],\n",
       "       [0.48164716],\n",
       "       [0.4517898 ],\n",
       "       [0.46433702],\n",
       "       [0.5458818 ],\n",
       "       [0.51414096],\n",
       "       [0.52602684],\n",
       "       [0.49479327],\n",
       "       [0.475079  ],\n",
       "       [0.4884198 ],\n",
       "       [0.5380374 ],\n",
       "       [0.51168597],\n",
       "       [0.49861395],\n",
       "       [0.5108601 ],\n",
       "       [0.5170536 ],\n",
       "       [0.4939914 ],\n",
       "       [0.5129061 ],\n",
       "       [0.511719  ],\n",
       "       [0.46018824],\n",
       "       [0.4779932 ],\n",
       "       [0.52010536],\n",
       "       [0.52361894],\n",
       "       [0.50723565],\n",
       "       [0.5278076 ],\n",
       "       [0.46268243],\n",
       "       [0.5473373 ],\n",
       "       [0.51901937],\n",
       "       [0.45822096],\n",
       "       [0.51237285],\n",
       "       [0.5334267 ],\n",
       "       [0.51030827],\n",
       "       [0.4789081 ],\n",
       "       [0.4811574 ],\n",
       "       [0.49935606],\n",
       "       [0.48851407],\n",
       "       [0.49321812],\n",
       "       [0.53053176],\n",
       "       [0.50110185],\n",
       "       [0.48187885],\n",
       "       [0.4729576 ],\n",
       "       [0.51929694],\n",
       "       [0.5323519 ],\n",
       "       [0.5087909 ],\n",
       "       [0.47493902],\n",
       "       [0.49118686],\n",
       "       [0.48761997],\n",
       "       [0.51121914],\n",
       "       [0.5004841 ],\n",
       "       [0.5017498 ],\n",
       "       [0.52174044],\n",
       "       [0.47476017],\n",
       "       [0.5104085 ],\n",
       "       [0.47329134],\n",
       "       [0.524505  ],\n",
       "       [0.527748  ],\n",
       "       [0.46146598],\n",
       "       [0.5350406 ],\n",
       "       [0.5500648 ],\n",
       "       [0.5078217 ],\n",
       "       [0.5355064 ],\n",
       "       [0.4654189 ],\n",
       "       [0.51704276],\n",
       "       [0.5247433 ],\n",
       "       [0.5094279 ],\n",
       "       [0.47245452],\n",
       "       [0.5209656 ],\n",
       "       [0.52871   ],\n",
       "       [0.52416414],\n",
       "       [0.4869327 ],\n",
       "       [0.46144554],\n",
       "       [0.49207017],\n",
       "       [0.49090293],\n",
       "       [0.47749266],\n",
       "       [0.46033788],\n",
       "       [0.48846915],\n",
       "       [0.49958968],\n",
       "       [0.46580696],\n",
       "       [0.4899628 ],\n",
       "       [0.48139852],\n",
       "       [0.4799226 ],\n",
       "       [0.5288267 ],\n",
       "       [0.4902553 ],\n",
       "       [0.48584664],\n",
       "       [0.50782335],\n",
       "       [0.52236617],\n",
       "       [0.5408492 ],\n",
       "       [0.49593973],\n",
       "       [0.5239674 ],\n",
       "       [0.47566432],\n",
       "       [0.48458666],\n",
       "       [0.55000764],\n",
       "       [0.5057502 ],\n",
       "       [0.5198504 ],\n",
       "       [0.4975971 ],\n",
       "       [0.5406801 ],\n",
       "       [0.5270394 ],\n",
       "       [0.50358284],\n",
       "       [0.5035368 ],\n",
       "       [0.5101074 ],\n",
       "       [0.4824064 ],\n",
       "       [0.49634007],\n",
       "       [0.5498599 ],\n",
       "       [0.52784485],\n",
       "       [0.5359731 ],\n",
       "       [0.5086191 ],\n",
       "       [0.46851137],\n",
       "       [0.5146376 ],\n",
       "       [0.46713534],\n",
       "       [0.5033815 ],\n",
       "       [0.48236826],\n",
       "       [0.5221095 ],\n",
       "       [0.47429317],\n",
       "       [0.49702215],\n",
       "       [0.521678  ],\n",
       "       [0.5029949 ],\n",
       "       [0.5301045 ],\n",
       "       [0.47997192],\n",
       "       [0.51041555],\n",
       "       [0.5152267 ],\n",
       "       [0.5278215 ],\n",
       "       [0.4787606 ],\n",
       "       [0.50849783],\n",
       "       [0.5063693 ],\n",
       "       [0.46774173],\n",
       "       [0.48767307],\n",
       "       [0.47603375],\n",
       "       [0.47775096],\n",
       "       [0.512655  ],\n",
       "       [0.5149991 ],\n",
       "       [0.53243446],\n",
       "       [0.4844734 ],\n",
       "       [0.5287255 ],\n",
       "       [0.5070847 ],\n",
       "       [0.47968566],\n",
       "       [0.49848646],\n",
       "       [0.541301  ],\n",
       "       [0.47499546],\n",
       "       [0.50741315],\n",
       "       [0.49031508],\n",
       "       [0.5255841 ],\n",
       "       [0.52620286],\n",
       "       [0.54727316],\n",
       "       [0.52619064],\n",
       "       [0.4606172 ],\n",
       "       [0.502231  ],\n",
       "       [0.50783294],\n",
       "       [0.50226367],\n",
       "       [0.5318564 ],\n",
       "       [0.48580885],\n",
       "       [0.46220264],\n",
       "       [0.50314224],\n",
       "       [0.5389499 ],\n",
       "       [0.4855148 ],\n",
       "       [0.4957729 ],\n",
       "       [0.48626286],\n",
       "       [0.54212856],\n",
       "       [0.5124714 ],\n",
       "       [0.455057  ],\n",
       "       [0.5067978 ],\n",
       "       [0.4911836 ],\n",
       "       [0.513334  ],\n",
       "       [0.4814751 ],\n",
       "       [0.48666984],\n",
       "       [0.5184737 ],\n",
       "       [0.5436188 ],\n",
       "       [0.49214083],\n",
       "       [0.5489316 ],\n",
       "       [0.48879   ],\n",
       "       [0.46440238],\n",
       "       [0.55235875],\n",
       "       [0.5371337 ],\n",
       "       [0.5237881 ],\n",
       "       [0.54411757],\n",
       "       [0.5229323 ],\n",
       "       [0.48651668],\n",
       "       [0.45833945],\n",
       "       [0.52659   ],\n",
       "       [0.51747775],\n",
       "       [0.5076524 ],\n",
       "       [0.4825022 ],\n",
       "       [0.53049225],\n",
       "       [0.5086599 ],\n",
       "       [0.4808368 ],\n",
       "       [0.5085784 ],\n",
       "       [0.5149726 ],\n",
       "       [0.49489078],\n",
       "       [0.5098386 ],\n",
       "       [0.5350071 ],\n",
       "       [0.48993215],\n",
       "       [0.51126254],\n",
       "       [0.49082354],\n",
       "       [0.47585094],\n",
       "       [0.49541864],\n",
       "       [0.52746034],\n",
       "       [0.4955168 ],\n",
       "       [0.50555503],\n",
       "       [0.4930048 ],\n",
       "       [0.49585393],\n",
       "       [0.5091609 ],\n",
       "       [0.4681364 ],\n",
       "       [0.50595796],\n",
       "       [0.5084988 ],\n",
       "       [0.48351336],\n",
       "       [0.5266975 ],\n",
       "       [0.5039466 ],\n",
       "       [0.5347762 ],\n",
       "       [0.4882059 ],\n",
       "       [0.4892656 ],\n",
       "       [0.47809032],\n",
       "       [0.46314543],\n",
       "       [0.5253636 ],\n",
       "       [0.47674963],\n",
       "       [0.49708232],\n",
       "       [0.5030552 ],\n",
       "       [0.48802537],\n",
       "       [0.5174074 ],\n",
       "       [0.4803222 ],\n",
       "       [0.49820465],\n",
       "       [0.5230931 ],\n",
       "       [0.51490986],\n",
       "       [0.50972855],\n",
       "       [0.48058107],\n",
       "       [0.5248438 ],\n",
       "       [0.47342595],\n",
       "       [0.5122305 ],\n",
       "       [0.49418002],\n",
       "       [0.4798603 ],\n",
       "       [0.5218892 ],\n",
       "       [0.49909988],\n",
       "       [0.46322998],\n",
       "       [0.46069133],\n",
       "       [0.5010959 ],\n",
       "       [0.5000206 ],\n",
       "       [0.52227265],\n",
       "       [0.53444576],\n",
       "       [0.52498627],\n",
       "       [0.48664182],\n",
       "       [0.48548967],\n",
       "       [0.50830436],\n",
       "       [0.47302172],\n",
       "       [0.47264665],\n",
       "       [0.48725107],\n",
       "       [0.4752761 ],\n",
       "       [0.47679687],\n",
       "       [0.47069553],\n",
       "       [0.552619  ],\n",
       "       [0.5508605 ],\n",
       "       [0.4832957 ],\n",
       "       [0.5371293 ],\n",
       "       [0.46172395],\n",
       "       [0.5394988 ],\n",
       "       [0.50198674],\n",
       "       [0.46929428],\n",
       "       [0.49574387],\n",
       "       [0.5121629 ],\n",
       "       [0.47629523],\n",
       "       [0.48009658],\n",
       "       [0.47894958],\n",
       "       [0.4942182 ],\n",
       "       [0.4935079 ],\n",
       "       [0.51224613],\n",
       "       [0.51397777],\n",
       "       [0.52117425],\n",
       "       [0.48981404],\n",
       "       [0.5443285 ],\n",
       "       [0.49041784],\n",
       "       [0.50290775],\n",
       "       [0.5228274 ],\n",
       "       [0.49938074],\n",
       "       [0.51046324],\n",
       "       [0.5251251 ],\n",
       "       [0.4767311 ],\n",
       "       [0.51227427],\n",
       "       [0.5100132 ],\n",
       "       [0.47437358],\n",
       "       [0.52446663],\n",
       "       [0.4700443 ],\n",
       "       [0.50089806],\n",
       "       [0.52061164],\n",
       "       [0.4788558 ],\n",
       "       [0.49073943],\n",
       "       [0.5311603 ],\n",
       "       [0.50591373],\n",
       "       [0.54451907],\n",
       "       [0.48887664],\n",
       "       [0.5386667 ],\n",
       "       [0.5272343 ],\n",
       "       [0.5035378 ],\n",
       "       [0.5245001 ],\n",
       "       [0.49370044],\n",
       "       [0.50973994],\n",
       "       [0.51195586],\n",
       "       [0.49758425],\n",
       "       [0.4646989 ],\n",
       "       [0.54086685],\n",
       "       [0.50064635],\n",
       "       [0.46453473],\n",
       "       [0.468031  ],\n",
       "       [0.49779215],\n",
       "       [0.5117004 ],\n",
       "       [0.5120629 ],\n",
       "       [0.51622546],\n",
       "       [0.4852911 ],\n",
       "       [0.50728893],\n",
       "       [0.48755634],\n",
       "       [0.5106622 ],\n",
       "       [0.5036346 ],\n",
       "       [0.4819121 ],\n",
       "       [0.47693673],\n",
       "       [0.5344932 ],\n",
       "       [0.51915336],\n",
       "       [0.49581817],\n",
       "       [0.4668456 ],\n",
       "       [0.5275254 ],\n",
       "       [0.5016295 ],\n",
       "       [0.48606864],\n",
       "       [0.54504335],\n",
       "       [0.4904739 ],\n",
       "       [0.5387047 ],\n",
       "       [0.50709546],\n",
       "       [0.5330602 ],\n",
       "       [0.53174186],\n",
       "       [0.46015784],\n",
       "       [0.52175653],\n",
       "       [0.46106973],\n",
       "       [0.46915984],\n",
       "       [0.48919302],\n",
       "       [0.46530345],\n",
       "       [0.5422331 ],\n",
       "       [0.45507383],\n",
       "       [0.46576178],\n",
       "       [0.51097363],\n",
       "       [0.5376642 ],\n",
       "       [0.5291525 ],\n",
       "       [0.4822387 ],\n",
       "       [0.5257276 ],\n",
       "       [0.48334423],\n",
       "       [0.5128272 ],\n",
       "       [0.5227595 ],\n",
       "       [0.49271795],\n",
       "       [0.5472585 ],\n",
       "       [0.5346963 ],\n",
       "       [0.48896372],\n",
       "       [0.46735987],\n",
       "       [0.48239407],\n",
       "       [0.5190464 ],\n",
       "       [0.5012999 ],\n",
       "       [0.48662916],\n",
       "       [0.540134  ],\n",
       "       [0.51262224],\n",
       "       [0.47507158],\n",
       "       [0.48429945],\n",
       "       [0.4870914 ],\n",
       "       [0.521869  ],\n",
       "       [0.5563569 ],\n",
       "       [0.53256136],\n",
       "       [0.5122025 ],\n",
       "       [0.46618125],\n",
       "       [0.4897318 ],\n",
       "       [0.480823  ],\n",
       "       [0.54480684],\n",
       "       [0.483735  ],\n",
       "       [0.48549172],\n",
       "       [0.5301869 ],\n",
       "       [0.46095785],\n",
       "       [0.4816821 ],\n",
       "       [0.49875274],\n",
       "       [0.50563   ],\n",
       "       [0.48947278],\n",
       "       [0.5158409 ],\n",
       "       [0.5421535 ],\n",
       "       [0.47928447],\n",
       "       [0.53593946],\n",
       "       [0.46167496],\n",
       "       [0.4756946 ],\n",
       "       [0.47777066],\n",
       "       [0.49404052],\n",
       "       [0.5303125 ],\n",
       "       [0.47657242],\n",
       "       [0.51341176],\n",
       "       [0.48140603],\n",
       "       [0.49427846],\n",
       "       [0.5104587 ],\n",
       "       [0.52169955],\n",
       "       [0.4821828 ],\n",
       "       [0.48939976],\n",
       "       [0.47248682],\n",
       "       [0.47896037],\n",
       "       [0.47425523],\n",
       "       [0.53015995],\n",
       "       [0.5082444 ],\n",
       "       [0.47534376],\n",
       "       [0.52566916],\n",
       "       [0.51255596],\n",
       "       [0.50819576],\n",
       "       [0.4869286 ],\n",
       "       [0.52657604],\n",
       "       [0.5256114 ],\n",
       "       [0.49295726],\n",
       "       [0.50200987],\n",
       "       [0.46816763],\n",
       "       [0.55016327],\n",
       "       [0.5149833 ],\n",
       "       [0.5314673 ],\n",
       "       [0.49082324],\n",
       "       [0.5216924 ],\n",
       "       [0.5545571 ],\n",
       "       [0.53215104],\n",
       "       [0.5364191 ],\n",
       "       [0.5350089 ],\n",
       "       [0.46469998],\n",
       "       [0.51242024],\n",
       "       [0.5043733 ],\n",
       "       [0.4766802 ],\n",
       "       [0.5015166 ],\n",
       "       [0.48886016],\n",
       "       [0.51970446],\n",
       "       [0.52806425],\n",
       "       [0.45972872],\n",
       "       [0.5484288 ],\n",
       "       [0.50358176],\n",
       "       [0.5539237 ],\n",
       "       [0.4877462 ],\n",
       "       [0.52385294],\n",
       "       [0.5485313 ],\n",
       "       [0.49799335],\n",
       "       [0.50448513],\n",
       "       [0.5225426 ],\n",
       "       [0.5029125 ],\n",
       "       [0.48024797],\n",
       "       [0.52227366],\n",
       "       [0.52891994],\n",
       "       [0.4936067 ],\n",
       "       [0.50168645],\n",
       "       [0.5209815 ],\n",
       "       [0.48016095],\n",
       "       [0.5427731 ],\n",
       "       [0.49869323],\n",
       "       [0.50591975],\n",
       "       [0.5147213 ],\n",
       "       [0.4986951 ],\n",
       "       [0.53061557],\n",
       "       [0.5297947 ],\n",
       "       [0.498614  ],\n",
       "       [0.4768071 ],\n",
       "       [0.5502837 ],\n",
       "       [0.52810407],\n",
       "       [0.47505295],\n",
       "       [0.49464753],\n",
       "       [0.5436857 ],\n",
       "       [0.47544122],\n",
       "       [0.5221591 ],\n",
       "       [0.49786228],\n",
       "       [0.52398014],\n",
       "       [0.48215592],\n",
       "       [0.5203779 ],\n",
       "       [0.4845187 ],\n",
       "       [0.492745  ],\n",
       "       [0.5203359 ],\n",
       "       [0.471707  ],\n",
       "       [0.50205725],\n",
       "       [0.5198227 ],\n",
       "       [0.52604973],\n",
       "       [0.4712403 ],\n",
       "       [0.48263365],\n",
       "       [0.5290199 ],\n",
       "       [0.5004052 ],\n",
       "       [0.5345811 ],\n",
       "       [0.5526748 ],\n",
       "       [0.46163577],\n",
       "       [0.47126052],\n",
       "       [0.5165931 ],\n",
       "       [0.5037091 ],\n",
       "       [0.49622947],\n",
       "       [0.49283046],\n",
       "       [0.4647277 ],\n",
       "       [0.47307828],\n",
       "       [0.5341846 ],\n",
       "       [0.49834603],\n",
       "       [0.48027587],\n",
       "       [0.51980793],\n",
       "       [0.52635896],\n",
       "       [0.5017327 ],\n",
       "       [0.52406836],\n",
       "       [0.4776216 ],\n",
       "       [0.53227234],\n",
       "       [0.49968094],\n",
       "       [0.50600135],\n",
       "       [0.46321198],\n",
       "       [0.49051586],\n",
       "       [0.47861898],\n",
       "       [0.51547086],\n",
       "       [0.5141815 ],\n",
       "       [0.49515307],\n",
       "       [0.46436083],\n",
       "       [0.5520941 ],\n",
       "       [0.5063397 ],\n",
       "       [0.5206455 ],\n",
       "       [0.52556145],\n",
       "       [0.5140562 ],\n",
       "       [0.4956039 ],\n",
       "       [0.5119333 ],\n",
       "       [0.49282965],\n",
       "       [0.55388546],\n",
       "       [0.5349741 ],\n",
       "       [0.47539532],\n",
       "       [0.48387277],\n",
       "       [0.49793002],\n",
       "       [0.5049293 ],\n",
       "       [0.49539796],\n",
       "       [0.51998174],\n",
       "       [0.47697482],\n",
       "       [0.5504799 ],\n",
       "       [0.47503102],\n",
       "       [0.517483  ],\n",
       "       [0.52961755],\n",
       "       [0.52367926],\n",
       "       [0.5318714 ],\n",
       "       [0.5029345 ],\n",
       "       [0.5204787 ],\n",
       "       [0.5413374 ],\n",
       "       [0.48555744],\n",
       "       [0.5416665 ],\n",
       "       [0.54906464],\n",
       "       [0.50169367],\n",
       "       [0.5370287 ],\n",
       "       [0.5169786 ],\n",
       "       [0.481041  ],\n",
       "       [0.51950777],\n",
       "       [0.47325107],\n",
       "       [0.49055317],\n",
       "       [0.4944141 ],\n",
       "       [0.47031674],\n",
       "       [0.488705  ],\n",
       "       [0.4978054 ],\n",
       "       [0.50758845],\n",
       "       [0.5046326 ],\n",
       "       [0.49294254],\n",
       "       [0.46840322],\n",
       "       [0.50002754],\n",
       "       [0.49447563],\n",
       "       [0.52847683],\n",
       "       [0.47195372],\n",
       "       [0.48789638],\n",
       "       [0.51847315],\n",
       "       [0.5326818 ],\n",
       "       [0.4565819 ],\n",
       "       [0.47538874],\n",
       "       [0.4840929 ],\n",
       "       [0.4891469 ],\n",
       "       [0.5450337 ],\n",
       "       [0.5149429 ],\n",
       "       [0.4979963 ],\n",
       "       [0.53492534],\n",
       "       [0.49986902],\n",
       "       [0.52383846],\n",
       "       [0.4773131 ],\n",
       "       [0.53478724],\n",
       "       [0.5324609 ],\n",
       "       [0.5096444 ],\n",
       "       [0.50187707],\n",
       "       [0.50556946],\n",
       "       [0.5227461 ],\n",
       "       [0.47484607],\n",
       "       [0.48887894]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)\n",
    "\n",
    "#It giving probablity, for eg there us 0.46 propbablity that there is 1 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c78ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(model.predict(X_test) >= 0.5,1,0)\n",
    "\n",
    "#0.5, probab value will be given bt domain expert\n",
    "#Or we can take probablity greater than 0.5, assign as 1 otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40de7ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(model.predict(X_test) >= 0.5,1,0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a41d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "pred = np.where(model.predict(X_test) >= 0.5,1,0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8577a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "818b1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "metrics.Accuracy(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b18b1e77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAccuracy(y_test, pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\accuracy_metrics.py:57\u001b[0m, in \u001b[0;36mAccuracy.__init__\u001b[1;34m(self, name, dtype)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(fn\u001b[38;5;241m=\u001b[39maccuracy, name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Metric should be maximized during optimization.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\reduction_metrics.py:187\u001b[0m, in \u001b[0;36mMeanMetricWrapper.__init__\u001b[1;34m(self, fn, name, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fn \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fn_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\reduction_metrics.py:123\u001b[0m, in \u001b[0;36mMean.__init__\u001b[1;34m(self, name, dtype)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_variable(\n\u001b[0;32m    125\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[0;32m    126\u001b[0m         initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mZeros(),\n\u001b[0;32m    127\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    128\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m     )\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_variable(\n\u001b[0;32m    131\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(),\n\u001b[0;32m    132\u001b[0m         initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mZeros(),\n\u001b[0;32m    133\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    134\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\metric.py:88\u001b[0m, in \u001b[0;36mMetric.__init__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name \u001b[38;5;129;01mor\u001b[39;00m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype \u001b[38;5;241m=\u001b[39m dtype \u001b[38;5;129;01mor\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "metrics.Accuracy(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac990f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f81e8954",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m F1Score(y_test, pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\f_score_metrics.py:309\u001b[0m, in \u001b[0;36mF1Score.__init__\u001b[1;34m(self, average, threshold, name, dtype)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    310\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[0;32m    311\u001b[0m         beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    312\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[0;32m    313\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    314\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\f_score_metrics.py:78\u001b[0m, in \u001b[0;36mFBetaScore.__init__\u001b[1;34m(self, average, beta, threshold, name, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Metric should be maximized during optimization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `average` argument value. Expected one of: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mNone, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: average=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta, \u001b[38;5;28mfloat\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "F1Score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de49a6b",
   "metadata": {},
   "source": [
    "### Categorical Cross Entropy Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb62ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=3000, n_features=20, n_classes=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c4d2987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 20)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb1eea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(InputLayer(shape=(20,)))\n",
    "model1.add(Dense(units=4, activation='sigmoid', use_bias=True))\n",
    "model1.add(Dense(units=6, activation='sigmoid', use_bias=True))\n",
    "model1.add(Dense(units=2, activation='softmax', use_bias=True))\n",
    "\n",
    "#Output Layer will contain neoron == no of class(k)\n",
    "#There will be two probabality of success and failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3f4ce5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m84\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m30\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m14\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ce38bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55873b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=sgd, loss ='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d24d101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(10,), output.shape=(10, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:547\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m     )\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(10,), output.shape=(10, 2)"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c492c",
   "metadata": {},
   "source": [
    "* **To handle this error there would be two reason**\n",
    "* **1. Check and use correct loss**\n",
    "* **2. Check how many neuron in OL**\n",
    "\n",
    "* **Solution is :- Use sparse_categorical_crossentropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95eb3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=sgd, loss ='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "065c8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5086 - loss: 0.6912 - val_accuracy: 0.4625 - val_loss: 0.6991\n",
      "Epoch 2/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5155 - loss: 0.6857 - val_accuracy: 0.4625 - val_loss: 0.6939\n",
      "Epoch 3/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5246 - loss: 0.6817 - val_accuracy: 0.4729 - val_loss: 0.6903\n",
      "Epoch 4/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5278 - loss: 0.6811 - val_accuracy: 0.5000 - val_loss: 0.6878\n",
      "Epoch 5/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 0.6826 - val_accuracy: 0.5354 - val_loss: 0.6860\n",
      "Epoch 6/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5721 - loss: 0.6814 - val_accuracy: 0.5500 - val_loss: 0.6847\n",
      "Epoch 7/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.6801 - val_accuracy: 0.5604 - val_loss: 0.6835\n",
      "Epoch 8/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 0.6786 - val_accuracy: 0.5688 - val_loss: 0.6825\n",
      "Epoch 9/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.6798 - val_accuracy: 0.5875 - val_loss: 0.6817\n",
      "Epoch 10/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6034 - loss: 0.6784 - val_accuracy: 0.5896 - val_loss: 0.6810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x133d6559210>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54ccc2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6077 - loss: 0.6775 - val_accuracy: 0.5958 - val_loss: 0.6803\n",
      "Epoch 2/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6758 - val_accuracy: 0.6021 - val_loss: 0.6796\n",
      "Epoch 3/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.6753 - val_accuracy: 0.6042 - val_loss: 0.6789\n",
      "Epoch 4/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 0.6757 - val_accuracy: 0.6104 - val_loss: 0.6782\n",
      "Epoch 5/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6368 - loss: 0.6765 - val_accuracy: 0.6146 - val_loss: 0.6777\n",
      "Epoch 6/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.6742 - val_accuracy: 0.6208 - val_loss: 0.6772\n",
      "Epoch 7/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6530 - loss: 0.6737 - val_accuracy: 0.6208 - val_loss: 0.6765\n",
      "Epoch 8/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.6732 - val_accuracy: 0.6292 - val_loss: 0.6759\n",
      "Epoch 9/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.6711 - val_accuracy: 0.6375 - val_loss: 0.6753\n",
      "Epoch 10/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.6708 - val_accuracy: 0.6417 - val_loss: 0.6747\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be5da2",
   "metadata": {},
   "source": [
    "**Internally we use sparse categ cross entr because for categ cross ent OHE in necesssory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4dfb6",
   "metadata": {},
   "source": [
    "### Categorical Cross Entropy:- Encoded as OHE and use Categ Cross Ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d33d865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75f31438",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_trainohe = ohe.fit_transform(y_train.reshape((2400,1)))\n",
    "\n",
    "#To convert 1d array to 2d array, becz OHE reqired 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3a95902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "820fd19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06191b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(InputLayer(shape=(20,)))\n",
    "model2.add(Dense(units=4, activation='sigmoid', use_bias=True))\n",
    "model2.add(Dense(units=6, activation='sigmoid', use_bias=True))\n",
    "model2.add(Dense(units=2, activation='softmax', use_bias=True))\n",
    "\n",
    "#Output Layer will contain neoron == no of class(k)\n",
    "#There will be two probabality of success and failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ffbb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='sgd', loss ='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7121d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5008 - loss: 0.7735 - val_accuracy: 0.6417 - val_loss: 0.6806\n",
      "Epoch 2/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 0.6814 - val_accuracy: 0.5875 - val_loss: 0.6796\n",
      "Epoch 3/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6710 - loss: 0.6766 - val_accuracy: 0.7083 - val_loss: 0.6709\n",
      "Epoch 4/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.6683 - val_accuracy: 0.7583 - val_loss: 0.6618\n",
      "Epoch 5/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.6607 - val_accuracy: 0.7604 - val_loss: 0.6526\n",
      "Epoch 6/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7535 - loss: 0.6514 - val_accuracy: 0.7729 - val_loss: 0.6414\n",
      "Epoch 7/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.6368 - val_accuracy: 0.7833 - val_loss: 0.6259\n",
      "Epoch 8/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.6259 - val_accuracy: 0.8000 - val_loss: 0.6118\n",
      "Epoch 9/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.6084 - val_accuracy: 0.8083 - val_loss: 0.5944\n",
      "Epoch 10/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.5904 - val_accuracy: 0.8167 - val_loss: 0.5757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x133d807b990>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_trainohe, batch_size=10, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b63eed34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model2.predict(X_test),axis=1).shape\n",
    "\n",
    "#to convert 2d to 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8eabee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(model2.predict(X_test),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e09dcb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metrics\u001b[38;5;241m.\u001b[39mF1Score(y_test, pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\f_score_metrics.py:309\u001b[0m, in \u001b[0;36mF1Score.__init__\u001b[1;34m(self, average, threshold, name, dtype)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    310\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[0;32m    311\u001b[0m         beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    312\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[0;32m    313\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    314\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\f_score_metrics.py:78\u001b[0m, in \u001b[0;36mFBetaScore.__init__\u001b[1;34m(self, average, beta, threshold, name, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Metric should be maximized during optimization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `average` argument value. Expected one of: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mNone, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: average=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta, \u001b[38;5;28mfloat\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "metrics.F1Score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487ecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
